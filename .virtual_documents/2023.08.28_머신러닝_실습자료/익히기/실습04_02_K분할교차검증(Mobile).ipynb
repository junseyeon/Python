











# 라이브러리 불러오기
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings

warnings.filterwarnings(action='ignore')
%config InlineBackend.figure_format='retina'


# 데이터 읽어오기
path = 'https://raw.githubusercontent.com/Jangrae/csv/master/mobile_cust_churn.csv'
data = pd.read_csv(path)





# 데이터 살펴보기
data.head()





# 기술통계 확인
data.describe()








# 제거 대상: id


# 변수 제거
data.drop('id', axis=1, inplace=True)

# 확인
data





# Target 설정
target = 'CHURN'

# 데이터 분리
x = data.drop(target, axis=1)
y = data[target]






# 가변수화 대상: 'REPORTED_SATISFACTION, REPORTED_USAGE_LEVEL, CONSIDERING_CHANGE_OF_PLAN]
col = ['REPORTED_SATISFACTION', 'REPORTED_USAGE_LEVEL', 'CONSIDERING_CHANGE_OF_PLAN']

# 가변수화
x = pd.get_dummies(x, columns=col, drop_first=True)


# 확인
x





# 모듈 불러오기
from sklearn.model_selection import train_test_split

# 7:3으로 분리
x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3, random_state=1)





# 모듈 불러오기
from sklearn.preprocessing import MinMaxScaler

# 정규화

scaler = MinMaxScaler()
x_train_s = scaler.fit_transform(x_train)
x_test_s = scaler.fit(x_test)








# 불러오기
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import cross_val_score

# 선언하기
model = KNeighborsClassifier()

# 검증하기
cv = cross_val_score(model, x_train_s, y_train, cv = 5, scoring = 'accuracy')

# 확인
print(cv)
print(cv.mean(), cv.std())
result = {}
result['KNN'] = cv.mean()





# 불러오기

from sklearn.tree import DecisionTreeClassifier

# 선언하기
model = DecisionTreeClassifier(random_state=1)  #max_depth

# 검증하기
cv = cross_val_score(model, x_train, y_train, cv=5)

# 확인
print(cv)
print(cv.mean(), cv.std())
result['DecisionTree'] = cv.mean()





# 불러오기
from sklearn.linear_model import LogisticRegression


# 선언하기
model = LogisticRegression()

# 검증하기
cv = cross_val_score(model, x_train, y_train, cv=5)

# 확인
print(cv)
print(cv.mean(), cv.std())
result['LogisticRegression'] = cv.mean()


result


from sklearn.metrics import classification_report
model = LogisticRegression()
model.fit(x_train, y_train)
y_pred = model.predict(x_test)

print(classification_report(y_test, y_pred))  # 0.63 0.63 으로 동일하다. 



